{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf810
{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red255\green255\blue255;}
{\*\expandedcolortbl;;\csgray\c0;\csgray\c100000;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f0\fs22 \cf2 \cb3 \CocoaLigature0 val sqlContext = new org.apache.spark.sql.SQLContext(sc)\
//Read CSV data file\
val stdf = sqlContext.read.format("com.databricks.spark.csv").option("header", "true").option("inferSchema", "true").load("student_dataset.txt")\
//What is the count of students per grade in the school?\
stdf.groupBy("grade").count().show()\
//Find the average of each student\
stdf.groupBy("name","grade").avg("marks").show()\
//What is the average score of students in each subject across all grades?\
stdf.groupBy("subject").avg("marks").show()\
//What is the average score of students in each subject per grade?\
stdf.groupBy("subject","grade").avg("marks").show()\
//For all students in grade-2, how many have average score greater than 50?\
val gr2df = stdf.filter(stdf("grade") === "grade-2").groupBy("grade").avg("marks").show()\
}